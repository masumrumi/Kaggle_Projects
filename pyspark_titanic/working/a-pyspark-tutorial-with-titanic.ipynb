{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://data.freehdw.com/ships-titanic-vehicles-best.jpg\"  Width=\"800\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This kernel will give a tutorial for starting out with PySpark using Titanic dataset. Let's get started. \n",
    "\n",
    "\n",
    "### Kernel Goals\n",
    "<a id=\"aboutthiskernel\"></a>\n",
    "***\n",
    "There are three primary goals of this kernel.\n",
    "- <b>Provide a tutorial for someone who is starting out with pyspark.\n",
    "- <b>Do an exploratory data analysis(EDA)</b> of titanic with visualizations and storytelling.  \n",
    "- <b>Predict</b>: Use machine learning classification models to predict the chances of passengers survival.\n",
    "\n",
    "### What is Spark, anyway?\n",
    "Spark is a platform for cluster computing. Spark lets us spread data and computations over clusters with multiple nodes (think of each node as a separate computer). Splitting up data makes it easier to work with very large datasets because each node only works with a small amount of data.\n",
    "As each node works on its own subset of the total data, it also carries out a part of the total calculations required, so that both data processing and computation are performed in parallel over the nodes in the cluster. It is a fact that parallel computation can make certain types of programming tasks much faster.\n",
    "\n",
    "Deciding whether or not Spark is the best solution for your problem takes some experience, but you can consider questions like:\n",
    "* Is my data too big to work with on a single machine?\n",
    "* Can my calculations be easily parallelized?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/titanic/test.csv\n",
      "../input/titanic/train.csv\n",
      "../input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.2.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyspark) (0.10.9.2)\r\n"
     ]
    }
   ],
   "source": [
    "## installing pyspark\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (6.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyarrow) (1.21.4)\r\n"
     ]
    }
   ],
   "source": [
    "## installing pyarrow\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in using Spark is connecting to a cluster. In practice, the cluster will be hosted on a remote machine that's connected to all other nodes. There will be one computer, called the master that manages splitting up the data and the computations. The master is connected to the rest of the computers in the cluster, which are called worker. The master sends the workers data and calculations to run, and they send their results back to the master.\n",
    "\n",
    "We definitely don't need may clusters for Titanic dataset. In addition to that, the syntax for running locally or using many clusters are pretty similar. To start working with Spark DataFrames, we first have to create a SparkSession object from SparkContext. We can think of the SparkContext as the connection to the cluster and SparkSession as the interface with that connection. Let's create a SparkSession. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner Tutorial\n",
    "This part is solely for beginners. I recommend starting from here to get a good understanding of the flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('tutorial').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv('../input/titanic/train.csv', header = True, inferSchema=True)\n",
    "df_test = spark.read.csv('../input/titanic/test.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = df_train.alias(\"titanic_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## So, what is df_train?\n",
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## As you can see it's a Spark dataframe. Let's take a look at the preview of the dataset. \n",
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Johnston, Miss. Catherine Helen \"\"Carrie\"\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888       \"Johnston, Miss. Catherine Helen \"\"Carrie\"\"\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500  None        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250  None        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500  None        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000  None        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500  None        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500  None        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## It looks a bit messi. See what I did there? ;). Anyway, how about using .toPandas() for change. \n",
    "df_train.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use the toPandas() in a riddiculous amount as you will see in this kernel. \n",
    "# It is just convenient and doesn't put a lot of constran in my eye. \n",
    "## in addition to that if you know pandas, this can be very helpful \n",
    "## for checking your work.\n",
    "## how about a summary. \n",
    "result = df_train.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.3838383838383838</td>\n",
       "      <td>2.308641975308642</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>29.69911764705882</td>\n",
       "      <td>0.5230078563411896</td>\n",
       "      <td>0.38159371492704824</td>\n",
       "      <td>260318.54916792738</td>\n",
       "      <td>32.2042079685746</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>257.3538420152301</td>\n",
       "      <td>0.48659245426485753</td>\n",
       "      <td>0.8360712409770491</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14.526497332334035</td>\n",
       "      <td>1.1027434322934315</td>\n",
       "      <td>0.8060572211299488</td>\n",
       "      <td>471609.26868834975</td>\n",
       "      <td>49.69342859718089</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>891</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        PassengerId             Survived              Pclass  \\\n",
       "0   count                891                  891                 891   \n",
       "1    mean              446.0   0.3838383838383838   2.308641975308642   \n",
       "2  stddev  257.3538420152301  0.48659245426485753  0.8360712409770491   \n",
       "3     min                  1                    0                   1   \n",
       "4     max                891                    1                   3   \n",
       "\n",
       "                                               Name     Sex  \\\n",
       "0                                               891     891   \n",
       "1                                              None    None   \n",
       "2                                              None    None   \n",
       "3  \"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"  female   \n",
       "4                       van Melkebeke, Mr. Philemon    male   \n",
       "\n",
       "                  Age               SibSp                Parch  \\\n",
       "0                 714                 891                  891   \n",
       "1   29.69911764705882  0.5230078563411896  0.38159371492704824   \n",
       "2  14.526497332334035  1.1027434322934315   0.8060572211299488   \n",
       "3                0.42                   0                    0   \n",
       "4                80.0                   8                    6   \n",
       "\n",
       "               Ticket               Fare Cabin Embarked  \n",
       "0                 891                891   204      889  \n",
       "1  260318.54916792738   32.2042079685746  None     None  \n",
       "2  471609.26868834975  49.69342859718089  None     None  \n",
       "3              110152                0.0   A10        C  \n",
       "4           WE/P 5735           512.3292     T        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the total row count\n",
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <class 'pandas.core.frame.DataFrame'>\n",
      "After: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# We can also convert a pandas dataframe to spark dataframe. Here is how we do it. \n",
    "print(f\"Before: {type(result)}\")\n",
    "spark_temp = spark.createDataFrame(result)\n",
    "print(f\"After: {type(spark_temp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cool, Let's print the schema of the df using .printSchema()\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar approach\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the real world is not this clean. We often have to create our own schema and implement it. We will describe more about it in the future. Since we are talking about schema, are you wondering if you would be able to implement sql with Spark?. Yes, you can. \n",
    "\n",
    "One of the best advantage of Spark is that you can run sql commands to do analysis. If you are like that nifty co-worker of mine, you would probably want to use sql with spark. Let's do an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Mark</td>\n",
       "      <td>male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Emily Borie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Ryerson, Miss. Susan Parker \"\"Suzette\"\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Baxter, Mr. Quigg Edmond</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                                       Name  \\\n",
       "0          738         1       1                     Lesurer, Mr. Gustave J   \n",
       "1          259         1       1                           Ward, Miss. Anna   \n",
       "2          680         1       1         Cardeza, Mr. Thomas Drake Martinez   \n",
       "3          342         1       1             Fortune, Miss. Alice Elizabeth   \n",
       "4           89         1       1                 Fortune, Miss. Mabel Helen   \n",
       "5          439         0       1                          Fortune, Mr. Mark   \n",
       "6           28         0       1             Fortune, Mr. Charles Alexander   \n",
       "7          312         1       1                 Ryerson, Miss. Emily Borie   \n",
       "8          743         1       1  \"Ryerson, Miss. Susan Parker \"\"Suzette\"\"\"   \n",
       "9          119         0       1                   Baxter, Mr. Quigg Edmond   \n",
       "\n",
       "      Sex   Age  SibSp  Parch    Ticket      Fare            Cabin Embarked  \n",
       "0    male  35.0      0      0  PC 17755  512.3292             B101        C  \n",
       "1  female  35.0      0      0  PC 17755  512.3292             None        C  \n",
       "2    male  36.0      0      1  PC 17755  512.3292      B51 B53 B55        C  \n",
       "3  female  24.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "4  female  23.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "5    male  64.0      1      4     19950  263.0000      C23 C25 C27        S  \n",
       "6    male  19.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "7  female  18.0      2      2  PC 17608  262.3750  B57 B59 B63 B66        C  \n",
       "8  female  21.0      2      2  PC 17608  262.3750  B57 B59 B63 B66        C  \n",
       "9    male  24.0      0      1  PC 17558  247.5208          B58 B60        C  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## First, we need to register a sql temporary view.\n",
    "df_train.createOrReplaceTempView(\"mytable\");\n",
    "\n",
    "## Then, we use spark.sql and write sql inside it, which returns a spark Dataframe.  \n",
    "result = spark.sql(\"SELECT * FROM mytable ORDER BY Fare DESC LIMIT 10\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can also register another sql temp view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.createOrReplaceTempView(\"df_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have registered two tables with in this spark session, wondering how we can see which once are registered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='df_test', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='mytable', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+\n",
      "|namespace|viewName|isTemporary|\n",
      "+---------+--------+-----------+\n",
      "|         | df_test|       true|\n",
      "|         | mytable|       true|\n",
      "+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly\n",
    "spark.sql(\"SHOW views\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0| 363272|    7.0| null|       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0| 240276| 9.6875| null|       Q|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0| 315154| 8.6625| null|       S|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|3101298|12.2875| null|       S|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also create spark dataframe out of these tables using spark.table\n",
    "temp_table = spark.table(\"df_test\")\n",
    "print(type(temp_table))\n",
    "temp_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretty cool, We will dive deep in sql later. \n",
    "# Let's go back to dataFrame and do some nitty-gritty stuff. \n",
    "# What if want the column names only. \n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Age'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about just a column?\n",
    "df_train['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Age'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Age|\n",
      "+----+\n",
      "|22.0|\n",
      "|38.0|\n",
      "|26.0|\n",
      "|35.0|\n",
      "|35.0|\n",
      "|null|\n",
      "|54.0|\n",
      "| 2.0|\n",
      "|27.0|\n",
      "|14.0|\n",
      "| 4.0|\n",
      "|58.0|\n",
      "|20.0|\n",
      "|39.0|\n",
      "|14.0|\n",
      "|55.0|\n",
      "| 2.0|\n",
      "|null|\n",
      "|31.0|\n",
      "|null|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Well, that's not what we pandas users have expected. \n",
    "# Yes, in order to get a column we need to use select().  \n",
    "# df.select(df['Age']).show()\n",
    "df_train.select('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| Age|   Fare|\n",
      "+----+-------+\n",
      "|22.0|   7.25|\n",
      "|38.0|71.2833|\n",
      "|26.0|  7.925|\n",
      "|35.0|   53.1|\n",
      "|35.0|   8.05|\n",
      "|null| 8.4583|\n",
      "|54.0|51.8625|\n",
      "| 2.0| 21.075|\n",
      "|27.0|11.1333|\n",
      "|14.0|30.0708|\n",
      "| 4.0|   16.7|\n",
      "|58.0|  26.55|\n",
      "|20.0|   8.05|\n",
      "|39.0| 31.275|\n",
      "|14.0| 7.8542|\n",
      "|55.0|   16.0|\n",
      "| 2.0| 29.125|\n",
      "|null|   13.0|\n",
      "|31.0|   18.0|\n",
      "|null|  7.225|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## What if we want multiple columns?\n",
    "df_train.select(['Age', 'Fare']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| Age|   Fare|\n",
      "+----+-------+\n",
      "|22.0|   7.25|\n",
      "|38.0|71.2833|\n",
      "|26.0|  7.925|\n",
      "|35.0|   53.1|\n",
      "|35.0|   8.05|\n",
      "|null| 8.4583|\n",
      "|54.0|51.8625|\n",
      "| 2.0| 21.075|\n",
      "|27.0|11.1333|\n",
      "|14.0|30.0708|\n",
      "| 4.0|   16.7|\n",
      "|58.0|  26.55|\n",
      "|20.0|   8.05|\n",
      "|39.0| 31.275|\n",
      "|14.0| 7.8542|\n",
      "|55.0|   16.0|\n",
      "| 2.0| 29.125|\n",
      "|null|   13.0|\n",
      "|31.0|   18.0|\n",
      "|null|  7.225|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly \n",
    "df_train[['Age', 'Fare']].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| Age|   Fare|\n",
      "+----+-------+\n",
      "|22.0|   7.25|\n",
      "|38.0|71.2833|\n",
      "|26.0|  7.925|\n",
      "|35.0|   53.1|\n",
      "|35.0|   8.05|\n",
      "|null| 8.4583|\n",
      "|54.0|51.8625|\n",
      "| 2.0| 21.075|\n",
      "|27.0|11.1333|\n",
      "|14.0|30.0708|\n",
      "| 4.0|   16.7|\n",
      "|58.0|  26.55|\n",
      "|20.0|   8.05|\n",
      "|39.0| 31.275|\n",
      "|14.0| 7.8542|\n",
      "|55.0|   16.0|\n",
      "| 2.0| 29.125|\n",
      "|null|   13.0|\n",
      "|31.0|   18.0|\n",
      "|null|  7.225|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or \n",
    "df_train[df_train.Age, \n",
    "         df_train.Fare].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see pyspark dataframe syntax is pretty simple with a lot of ways to implement. Which syntex is best implemented depends on what we are trying to accomplish. I will discuss more on this as we go on. Now let's see how we can access a row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## returns a list. let's get the item in the list\n",
    "row = df_train.head(1)[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PassengerId': 1,\n",
       " 'Survived': 0,\n",
       " 'Pclass': 3,\n",
       " 'Name': 'Braund, Mr. Owen Harris',\n",
       " 'Sex': 'male',\n",
       " 'Age': 22.0,\n",
       " 'SibSp': 1,\n",
       " 'Parch': 0,\n",
       " 'Ticket': 'A/5 21171',\n",
       " 'Fare': 7.25,\n",
       " 'Cabin': None,\n",
       " 'Embarked': 'S'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## row can be converted into dict using .asDict()\n",
    "row.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Then the value can be accessed from the row dictionaly. \n",
    "row.asDict()['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Braund, Mr. Owen Harris'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## similarly\n",
    "row.asDict()['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>newA</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  newA  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let's say we want to change the name of a column. we can use withColumnRenamed\n",
    "# df.withColumnRenamed('exsisting name', 'anticipated name');\n",
    "df_train.withColumnRenamed(\"Age\", \"newA\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|  27.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|91.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282| 27.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   73.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|  28.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's say we want to modify a column, for example, add in this case, adding $20 with every fare. \n",
    "## df.withColumn('existing column', 'calculation with the column(we have to put df not just column)')\n",
    "## so not df.withColumn('Fare', 'Fare' +20).show()\n",
    "df_train.withColumn('Fare', df_train['Fare']+20).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this change isn't permanent since we are not assigning it to any variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's say we want to get the average fare.\n",
    "# we will use the \"mean\" function from pyspark.sql.functions(this is where all the functions are stored) and\n",
    "# collect the data using \".collect()\" instead of using .show()\n",
    "# collect returns a list so we need to get the value from the list using index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.2042079685746"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "fare_mean = df_train.select(mean(\"Fare\")).collect()\n",
    "fare_mean[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.2042079685746"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare_mean = fare_mean[0][0]\n",
    "fare_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|  C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1| C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|  E46|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What if we want to filter data and see all fare above average. \n",
    "# there are two approaches of this, we can use sql syntex/passing a string\n",
    "# or just dataframe approach. \n",
    "df_train.filter(\"Fare > 32.20\" ).limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|  C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1| C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|  E46|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly \n",
    "df_train[df_train.Fare > 32.20].limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|  C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1| C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|  E46|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or we can use the dataframe approach\n",
    "df_train.filter(df_train['Fare'] > fare_mean).limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------+------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|   Ticket|  Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------+------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|male|22.0|    1|    0|A/5 21171|  7.25| null|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|male|35.0|    0|    0|   373450|  8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|male|null|    0|    0|   330877|8.4583| null|       Q|\n",
      "|          8|       0|     3|Palsson, Master. ...|male| 2.0|    3|    1|   349909|21.075| null|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|male|20.0|    0|    0|A/5. 2151|  8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------+------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## What if we want to filter by multiple columns.\n",
    "# passenger with below average fare with a sex equals male\n",
    "temp_df = df_train.filter((df_train['Fare'] < fare_mean) &\n",
    "          (df_train['Sex'] ==  'male')\n",
    "         )\n",
    "temp_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------+------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|   Ticket|  Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------+------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|male|22.0|    1|    0|A/5 21171|  7.25| null|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|male|35.0|    0|    0|   373450|  8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|male|null|    0|    0|   330877|8.4583| null|       Q|\n",
      "|          8|       0|     3|Palsson, Master. ...|male| 2.0|    3|    1|   349909|21.075| null|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|male|20.0|    0|    0|A/5. 2151|  8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------+------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly \n",
    "df_train[(df_train.Fare < fare_mean) & \n",
    "         (df_train.Sex == \"male\")].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "|         23|       1|     3|\"McGowan, Miss. A...|female|15.0|    0|    0|          330923| 8.0292| null|       Q|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# passenger with below average fare and are not male\n",
    "filter1_less_than_mean_fare = df_train['Fare'] < fare_mean\n",
    "filter2_sex_not_male = df_train['Sex'] != \"male\"\n",
    "df_train.filter((filter1_less_than_mean_fare) &\n",
    "                (filter2_sex_not_male)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "|         23|       1|     3|\"McGowan, Miss. A...|female|15.0|    0|    0|          330923| 8.0292| null|       Q|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also apply it this way\n",
    "# passenger with below fare and are not male\n",
    "# creating filters\n",
    "filter1_less_than_mean_fare = df_train['Fare'] < fare_mean\n",
    "filter2_sex_not_male = df_train['Sex'] != \"male\"\n",
    "# applying filters\n",
    "df_train.filter(filter1_less_than_mean_fare).filter(filter2_sex_not_male).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|PassengerId|   Fare|\n",
      "+-----------+-------+\n",
      "|          8| 21.075|\n",
      "|          9|11.1333|\n",
      "|         10|30.0708|\n",
      "|         11|   16.7|\n",
      "|         12|  26.55|\n",
      "|         14| 31.275|\n",
      "|         16|   16.0|\n",
      "|         17| 29.125|\n",
      "|         18|   13.0|\n",
      "|         19|   18.0|\n",
      "|         21|   26.0|\n",
      "|         22|   13.0|\n",
      "|         24|   35.5|\n",
      "|         25| 21.075|\n",
      "|         26|31.3875|\n",
      "|         31|27.7208|\n",
      "|         34|   10.5|\n",
      "|         39|   18.0|\n",
      "|         40|11.2417|\n",
      "|         42|   21.0|\n",
      "+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can also filter by using builtin functions.\n",
    "# between\n",
    "df_train.select(\"PassengerId\", \"Fare\").filter(df_train.Fare.between(10,40)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------------+\n",
      "|PassengerID|((Fare >= 10) AND (Fare <= 40))|\n",
      "+-----------+-------------------------------+\n",
      "|          1|                          false|\n",
      "|          2|                          false|\n",
      "|          3|                          false|\n",
      "|          4|                          false|\n",
      "|          5|                          false|\n",
      "|          6|                          false|\n",
      "|          7|                          false|\n",
      "|          8|                           true|\n",
      "|          9|                           true|\n",
      "|         10|                           true|\n",
      "|         11|                           true|\n",
      "|         12|                           true|\n",
      "|         13|                          false|\n",
      "|         14|                           true|\n",
      "|         15|                          false|\n",
      "|         16|                           true|\n",
      "|         17|                           true|\n",
      "|         18|                           true|\n",
      "|         19|                           true|\n",
      "|         20|                          false|\n",
      "+-----------+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select(\"PassengerID\", df_train.Fare.between(10,40)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|PassengerId|                Name|\n",
      "+-----------+--------------------+\n",
      "|          1|Braund, Mr. Owen ...|\n",
      "|          2|Cumings, Mrs. Joh...|\n",
      "|          4|Futrelle, Mrs. Ja...|\n",
      "|          5|Allen, Mr. Willia...|\n",
      "|          6|    Moran, Mr. James|\n",
      "|          7|McCarthy, Mr. Tim...|\n",
      "|          9|Johnson, Mrs. Osc...|\n",
      "|         10|Nasser, Mrs. Nich...|\n",
      "|         13|Saundercock, Mr. ...|\n",
      "|         14|Andersson, Mr. An...|\n",
      "|         16|Hewlett, Mrs. (Ma...|\n",
      "|         18|Williams, Mr. Cha...|\n",
      "|         19|Vander Planke, Mr...|\n",
      "|         20|Masselmani, Mrs. ...|\n",
      "|         21|Fynney, Mr. Joseph J|\n",
      "|         22|Beesley, Mr. Lawr...|\n",
      "|         24|Sloper, Mr. Willi...|\n",
      "|         26|Asplund, Mrs. Car...|\n",
      "|         27|Emir, Mr. Farred ...|\n",
      "|         28|Fortune, Mr. Char...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# contains\n",
    "df_train.select(\"PassengerId\", \"Name\").filter(df_train.Name.contains(\"Mr\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|PassengerID|   Sex|\n",
      "+-----------+------+\n",
      "|          2|female|\n",
      "|          3|female|\n",
      "|          4|female|\n",
      "|          9|female|\n",
      "|         10|female|\n",
      "|         11|female|\n",
      "|         12|female|\n",
      "|         15|female|\n",
      "|         16|female|\n",
      "|         19|female|\n",
      "|         20|female|\n",
      "|         23|female|\n",
      "|         25|female|\n",
      "|         26|female|\n",
      "|         29|female|\n",
      "|         32|female|\n",
      "|         33|female|\n",
      "|         39|female|\n",
      "|         40|female|\n",
      "|         41|female|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# startswith \n",
    "df_train.select(\"PassengerID\", 'Sex').filter(df_train.Sex.startswith(\"fe\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|PassengerID|    Ticket|\n",
      "+-----------+----------+\n",
      "|          5|    373450|\n",
      "|         28|     19950|\n",
      "|         89|     19950|\n",
      "|        256|      2650|\n",
      "|        342|     19950|\n",
      "|        439|     19950|\n",
      "|        537|    113050|\n",
      "|        641|    350050|\n",
      "|        671|     29750|\n",
      "|        672|F.C. 12750|\n",
      "|        685|     29750|\n",
      "|        768|    364850|\n",
      "|        807|    112050|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# endswith\n",
    "df_train.select(\"PassengerID\", 'Ticket').filter(df_train.Ticket.endswith(\"50\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# isin\n",
    "df_train[df_train.PassengerId.isin([1,2,3])].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25| null|       S|\n",
      "|        195|       1|     1|Brown, Mrs. James...|female|44.0|    0|    0| PC 17610|27.7208|   B4|       C|\n",
      "|        222|       0|     2|Bracken, Mr. James H|  male|27.0|    0|    0|   220367|   13.0| null|       S|\n",
      "|        478|       0|     3|Braund, Mr. Lewis...|  male|29.0|    1|    0|     3460| 7.0458| null|       S|\n",
      "|        615|       0|     3|Brocklebank, Mr. ...|  male|35.0|    0|    0|   364512|   8.05| null|       S|\n",
      "|        671|       1|     2|Brown, Mrs. Thoma...|female|40.0|    1|    1|    29750|   39.0| null|       S|\n",
      "|        685|       0|     2|Brown, Mr. Thomas...|  male|60.0|    1|    1|    29750|   39.0| null|       S|\n",
      "|        729|       0|     2|Bryhl, Mr. Kurt A...|  male|25.0|    1|    0|   236853|   26.0| null|       S|\n",
      "|        767|       0|     1|Brewe, Dr. Arthur...|  male|null|    0|    0|   112379|   39.6| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like\n",
    "df_train[df_train.Name.like(\"Br%\")].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|substring(Name, 1, 5)|\n",
      "+---------------------+\n",
      "|                Braun|\n",
      "|                Cumin|\n",
      "|                Heikk|\n",
      "|                Futre|\n",
      "|                Allen|\n",
      "|                Moran|\n",
      "|                McCar|\n",
      "|                Palss|\n",
      "|                Johns|\n",
      "|                Nasse|\n",
      "|                Sands|\n",
      "|                Bonne|\n",
      "|                Saund|\n",
      "|                Ander|\n",
      "|                Vestr|\n",
      "|                Hewle|\n",
      "|                Rice,|\n",
      "|                Willi|\n",
      "|                Vande|\n",
      "|                Masse|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# substr\n",
    "df_train.select(df_train.Name.substr(1,5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|substring(Name, 1, 5)|\n",
      "+---------------------+\n",
      "|                Braun|\n",
      "|                Cumin|\n",
      "|                Heikk|\n",
      "|                Futre|\n",
      "|                Allen|\n",
      "|                Moran|\n",
      "|                McCar|\n",
      "|                Palss|\n",
      "|                Johns|\n",
      "|                Nasse|\n",
      "|                Sands|\n",
      "|                Bonne|\n",
      "|                Saund|\n",
      "|                Ander|\n",
      "|                Vestr|\n",
      "|                Hewle|\n",
      "|                Rice,|\n",
      "|                Willi|\n",
      "|                Vande|\n",
      "|                Masse|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly \n",
    "df_train[[df_train.Name.substr(1,5)]].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting thing about substr method is that we can't implement the following syntax while working with substr. This syntax is best implemented in a filter when the return values are boolean not a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[df_train.Name.substr(1,5)].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>avg(PassengerId)</th>\n",
       "      <th>avg(Survived)</th>\n",
       "      <th>avg(Pclass)</th>\n",
       "      <th>avg(Age)</th>\n",
       "      <th>avg(SibSp)</th>\n",
       "      <th>avg(Parch)</th>\n",
       "      <th>avg(Fare)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>461.597222</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>439.154786</td>\n",
       "      <td>0.242363</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>0.615071</td>\n",
       "      <td>0.393075</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>445.956522</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>20.662183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  avg(PassengerId)  avg(Survived)  avg(Pclass)   avg(Age)  \\\n",
       "0       1        461.597222       0.629630          1.0  38.233441   \n",
       "1       3        439.154786       0.242363          3.0  25.140620   \n",
       "2       2        445.956522       0.472826          2.0  29.877630   \n",
       "\n",
       "   avg(SibSp)  avg(Parch)  avg(Fare)  \n",
       "0    0.416667    0.356481  84.154687  \n",
       "1    0.615071    0.393075  13.675550  \n",
       "2    0.402174    0.380435  20.662183  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's group by Pclass and get the average fare price per Pclass.  \n",
    "df_train.groupBy(\"Pclass\").mean().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     3|13.675550101832997|\n",
      "|     2| 20.66218315217391|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## let's just look at the Pclass and avg(Fare)\n",
    "df_train.groupBy(\"Pclass\").mean().select('Pclass', 'avg(Fare)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     3|13.675550101832997|\n",
      "|     2| 20.66218315217391|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative way\n",
    "df_train.groupBy(\"Pclass\").mean(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       avg(Fare)|\n",
      "+----------------+\n",
      "|32.2042079685746|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## What if we want just the average of all fare, we can use .agg with the dataframe. \n",
    "df_train.agg({'Fare':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       avg(Fare)|\n",
      "+----------------+\n",
      "|32.2042079685746|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## another way this can be done is by importing \"mean\" funciton from pyspark.sql.functions\n",
    "from pyspark.sql.functions import mean\n",
    "df_train.select(mean(\"Fare\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     3|13.675550101832997|\n",
      "|     2| 20.66218315217391|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## we can also combine the few previous approaches to get similar results. \n",
    "temp = df_train.groupBy(\"Pclass\")\n",
    "temp.agg({\"Fare\": 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|Pclass|average fare|\n",
      "+------+------------+\n",
      "|     1|       84.15|\n",
      "|     3|       13.68|\n",
      "|     2|       20.66|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What if we want to format the results. \n",
    "# for example,\n",
    "# I want to rename the column. this will be accomplished using .alias() method.  \n",
    "# I want to format the number with only two decimals. this can be done using \"format_number\"\n",
    "from pyspark.sql.functions import format_number\n",
    "temp = df_train.groupBy(\"Pclass\")\n",
    "temp = temp.agg({\"Fare\": 'mean'})\n",
    "temp.select('Pclass', format_number(\"avg(Fare)\", 2).alias(\"average fare\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OrderBy\n",
    "There are many built in functions that we can use to do orderby in spark. Let's look at some of those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Frost, Mr. Anthony Wood \"\"Archie\"\"\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>675</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239856</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>733</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Knight, Mr. Robert J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239855</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B102</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reuchlin, Jonkheer. John George</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19972</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Campbell, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Parkes, Mr. Francis \"\"Frank\"\"\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112052</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Betros, Mr. Tannous</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2648</td>\n",
       "      <td>4.0125</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Nysveen, Mr. Johan Hansen</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345364</td>\n",
       "      <td>6.2375</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>844</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lemberopolous, Mr. Peter L</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2683</td>\n",
       "      <td>6.4375</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>819</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Holm, Mr. John Fredrik Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C 7075</td>\n",
       "      <td>6.4500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass                                  Name   Sex  \\\n",
       "0           180         0       3                   Leonard, Mr. Lionel  male   \n",
       "1           482         0       2  \"Frost, Mr. Anthony Wood \"\"Archie\"\"\"  male   \n",
       "2           414         0       2        Cunningham, Mr. Alfred Fleming  male   \n",
       "3           303         0       3       Johnson, Mr. William Cahoone Jr  male   \n",
       "4           264         0       1                 Harrison, Mr. William  male   \n",
       "5           675         0       2            Watson, Mr. Ennis Hastings  male   \n",
       "6           733         0       2                  Knight, Mr. Robert J  male   \n",
       "7           807         0       1                Andrews, Mr. Thomas Jr  male   \n",
       "8           816         0       1                      Fry, Mr. Richard  male   \n",
       "9           823         0       1       Reuchlin, Jonkheer. John George  male   \n",
       "10          467         0       2                 Campbell, Mr. William  male   \n",
       "11          272         1       3          Tornquist, Mr. William Henry  male   \n",
       "12          598         0       3                   Johnson, Mr. Alfred  male   \n",
       "13          278         0       2       \"Parkes, Mr. Francis \"\"Frank\"\"\"  male   \n",
       "14          634         0       1         Parr, Mr. William Henry Marsh  male   \n",
       "15          379         0       3                   Betros, Mr. Tannous  male   \n",
       "16          873         0       1              Carlsson, Mr. Frans Olof  male   \n",
       "17          327         0       3             Nysveen, Mr. Johan Hansen  male   \n",
       "18          844         0       3            Lemberopolous, Mr. Peter L  male   \n",
       "19          819         0       3      Holm, Mr. John Fredrik Alexander  male   \n",
       "\n",
       "     Age  SibSp  Parch  Ticket    Fare        Cabin Embarked  \n",
       "0   36.0      0      0    LINE  0.0000         None        S  \n",
       "1    NaN      0      0  239854  0.0000         None        S  \n",
       "2    NaN      0      0  239853  0.0000         None        S  \n",
       "3   19.0      0      0    LINE  0.0000         None        S  \n",
       "4   40.0      0      0  112059  0.0000          B94        S  \n",
       "5    NaN      0      0  239856  0.0000         None        S  \n",
       "6    NaN      0      0  239855  0.0000         None        S  \n",
       "7   39.0      0      0  112050  0.0000          A36        S  \n",
       "8    NaN      0      0  112058  0.0000         B102        S  \n",
       "9   38.0      0      0   19972  0.0000         None        S  \n",
       "10   NaN      0      0  239853  0.0000         None        S  \n",
       "11  25.0      0      0    LINE  0.0000         None        S  \n",
       "12  49.0      0      0    LINE  0.0000         None        S  \n",
       "13   NaN      0      0  239853  0.0000         None        S  \n",
       "14   NaN      0      0  112052  0.0000         None        S  \n",
       "15  20.0      0      0    2648  4.0125         None        C  \n",
       "16  33.0      0      0     695  5.0000  B51 B53 B55        S  \n",
       "17  61.0      0      0  345364  6.2375         None        S  \n",
       "18  34.5      0      0    2683  6.4375         None        C  \n",
       "19  43.0      0      0  C 7075  6.4500         None        S  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## What if I want to order by Fare in ascending order. \n",
    "df_train.orderBy(\"Fare\").limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+------+------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|Ticket|  Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+------+------+-----------+--------+\n",
      "|        272|       1|     3|Tornquist, Mr. Wi...|male|25.0|    0|    0|  LINE|   0.0|       null|       S|\n",
      "|        180|       0|     3| Leonard, Mr. Lionel|male|36.0|    0|    0|  LINE|   0.0|       null|       S|\n",
      "|        414|       0|     2|Cunningham, Mr. A...|male|null|    0|    0|239853|   0.0|       null|       S|\n",
      "|        278|       0|     2|\"Parkes, Mr. Fran...|male|null|    0|    0|239853|   0.0|       null|       S|\n",
      "|        675|       0|     2|Watson, Mr. Ennis...|male|null|    0|    0|239856|   0.0|       null|       S|\n",
      "|        733|       0|     2|Knight, Mr. Robert J|male|null|    0|    0|239855|   0.0|       null|       S|\n",
      "|        807|       0|     1|Andrews, Mr. Thom...|male|39.0|    0|    0|112050|   0.0|        A36|       S|\n",
      "|        816|       0|     1|    Fry, Mr. Richard|male|null|    0|    0|112058|   0.0|       B102|       S|\n",
      "|        823|       0|     1|Reuchlin, Jonkhee...|male|38.0|    0|    0| 19972|   0.0|       null|       S|\n",
      "|        467|       0|     2|Campbell, Mr. Wil...|male|null|    0|    0|239853|   0.0|       null|       S|\n",
      "|        264|       0|     1|Harrison, Mr. Wil...|male|40.0|    0|    0|112059|   0.0|        B94|       S|\n",
      "|        598|       0|     3| Johnson, Mr. Alfred|male|49.0|    0|    0|  LINE|   0.0|       null|       S|\n",
      "|        303|       0|     3|Johnson, Mr. Will...|male|19.0|    0|    0|  LINE|   0.0|       null|       S|\n",
      "|        634|       0|     1|Parr, Mr. William...|male|null|    0|    0|112052|   0.0|       null|       S|\n",
      "|        482|       0|     2|\"Frost, Mr. Antho...|male|null|    0|    0|239854|   0.0|       null|       S|\n",
      "|        379|       0|     3| Betros, Mr. Tannous|male|20.0|    0|    0|  2648|4.0125|       null|       C|\n",
      "|        873|       0|     1|Carlsson, Mr. Fra...|male|33.0|    0|    0|   695|   5.0|B51 B53 B55|       S|\n",
      "|        327|       0|     3|Nysveen, Mr. Joha...|male|61.0|    0|    0|345364|6.2375|       null|       S|\n",
      "|        844|       0|     3|Lemberopolous, Mr...|male|34.5|    0|    0|  2683|6.4375|       null|       C|\n",
      "|        819|       0|     3|Holm, Mr. John Fr...|male|43.0|    0|    0|C 7075|  6.45|       null|       S|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+------+------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly\n",
    "df_train.orderBy(df_train.Fare.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|        738|       1|     1|Lesurer, Mr. Gust...|  male|35.0|    0|    0|PC 17755|512.3292|       B101|       C|\n",
      "|        680|       1|     1|Cardeza, Mr. Thom...|  male|36.0|    0|    1|PC 17755|512.3292|B51 B53 B55|       C|\n",
      "|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292|       null|       C|\n",
      "|        439|       0|     1|   Fortune, Mr. Mark|  male|64.0|    1|    4|   19950|   263.0|C23 C25 C27|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|   19950|   263.0|C23 C25 C27|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What about descending order\n",
    "# df.orderBy(df['Fare'].desc()).limit(5).show()\n",
    "# dot notation\n",
    "df_train.orderBy(df_train.Fare.desc()).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.filter(df_train.Embarked.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerID|Embarked|\n",
      "+-----------+--------+\n",
      "|         62|    null|\n",
      "|        830|    null|\n",
      "|        204|       C|\n",
      "|         74|       C|\n",
      "|         97|       C|\n",
      "|         98|       C|\n",
      "|         66|       C|\n",
      "|        115|       C|\n",
      "|         65|       C|\n",
      "|        123|       C|\n",
      "|         31|       C|\n",
      "|        112|       C|\n",
      "|         35|       C|\n",
      "|         40|       C|\n",
      "|        119|       C|\n",
      "|         44|       C|\n",
      "|         53|       C|\n",
      "|        126|       C|\n",
      "|         58|       C|\n",
      "|        129|       C|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select('PassengerID','Embarked').orderBy(df_train.Embarked.asc_nulls_first()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerID=887, Embarked='S'),\n",
       " Row(PassengerID=888, Embarked='S'),\n",
       " Row(PassengerID=889, Embarked='S'),\n",
       " Row(PassengerID=62, Embarked=None),\n",
       " Row(PassengerID=830, Embarked=None)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.select('PassengerID','Embarked').orderBy(df_train.Embarked.asc_nulls_last()).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            2         1       1   \n",
       "1            4         1       1   \n",
       "2            7         0       1   \n",
       "3           11         1       3   \n",
       "4           12         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "2                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "3                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "4                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "   Parch    Ticket     Fare Cabin Embarked  \n",
       "0      0  PC 17599  71.2833   C85        C  \n",
       "1      0    113803  53.1000  C123        S  \n",
       "2      0     17463  51.8625   E46        S  \n",
       "3      1   PP 9549  16.7000    G6        S  \n",
       "4      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How do we deal with missing values. \n",
    "# df.na.drop(how=(\"any\"/\"all\"), thresh=(1,2,3,4,5...))\n",
    "df_train.na.drop(how=\"any\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have used Spark for a while now, this is a good time to learn about spark Catalog.\n",
    "# you can also totally skip this section since it is totally independed of what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='default', description='default database', locationUri='file:/Users/masumrumi/git_projects/Kaggle_Projects/pyspark_titanic/working/spark-warehouse')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the databases in the database. \n",
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the name of the current database\n",
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='df_test', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='mytable', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lists tables\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a table to the catalog\n",
    "df_train.createOrReplaceTempView(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='df_test', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='df_train', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='mytable', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list tables\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching\n",
    "# cached table \"df_train\"\n",
    "spark.catalog.cacheTable(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks if the table is cached\n",
    "spark.catalog.isCached(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"df_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets cahche df_test as well\n",
    "spark.catalog.cacheTable(\"df_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"df_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's uncache df_train\n",
    "spark.catalog.uncacheTable(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"df_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about clearing all cached tables at once. \n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a global temp view\n",
    "df_train.createGlobalTempView(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+\n",
      "|  namespace|viewName|isTemporary|\n",
      "+-----------+--------+-----------+\n",
      "|global_temp|df_train|       true|\n",
      "|           | df_test|       true|\n",
      "|           |df_train|       true|\n",
      "|           | mytable|       true|\n",
      "+-----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# listing all views in global_temp\n",
    "spark.sql(\"SHOW VIEWS IN global_temp;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping a table. \n",
    "spark.catalog.dropGlobalTempView(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+\n",
      "|namespace|viewName|isTemporary|\n",
      "+---------+--------+-----------+\n",
      "|         | df_test|       true|\n",
      "|         |df_train|       true|\n",
      "|         | mytable|       true|\n",
      "+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking that global temp view is dropped.\n",
    "spark.sql(\"SHOW VIEWS IN global_temp;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+\n",
      "|namespace|viewName|isTemporary|\n",
      "+---------+--------+-----------+\n",
      "|         | df_test|       true|\n",
      "|         | mytable|       true|\n",
      "+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking that global temp view is dropped.\n",
    "spark.sql(\"SHOW VIEWS IN global_temp;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+\n",
      "|namespace|viewName|isTemporary|\n",
      "+---------+--------+-----------+\n",
      "|         | df_test|       true|\n",
      "|         | mytable|       true|\n",
      "+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW VIEWS\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Values\n",
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the null values in cabin with \"N\".\n",
    "# df.fillna(value, subset=[]);\n",
    "df_train = df_train.na.fill('N', subset=['Cabin'])\n",
    "df_test = df_test.na.fill('N', subset=['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------------------+----+----+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Pclass|              Name| Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+------+------------------+----+----+-----+-----+------+----+-----+--------+\n",
      "|       1044|     3|Storey, Mr. Thomas|male|60.5|    0|    0|  3701|null|    N|       S|\n",
      "+-----------+------+------------------+----+----+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## how do we find out the rows with missing values?\n",
    "# we can use .where(condition) with .isNull()\n",
    "df_test.where(df_test['Fare'].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, We can take the average of the **Fare** column to fill in the NaN value. However, for the sake of learning and practicing, we will try something else. We can take the average of the values where **Pclass** is ***3***, **Sex** is ***male*** and **Embarked** is ***S***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = df_test.filter(\n",
    "    (df_test['Pclass'] == 3) &\n",
    "    (df_test.Embarked == 'S') &\n",
    "    (df_test.Sex == \"male\")\n",
    ")\n",
    "## filling in the null value in the fare column using Fare mean. \n",
    "df_test = df_test.na.fill(\n",
    "    missing_value.select(mean('Fare')).collect()[0][0],\n",
    "    subset=['Fare']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "+-----------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking\n",
    "df_test.where(df_test['Fare'].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
      "|         62|       1|     1| Icard, Miss. Amelie|female|38.0|    0|    0|113572|80.0|  B28|    null|\n",
      "|        830|       1|     1|Stone, Mrs. Georg...|female|62.0|    0|    0|113572|80.0|  B28|    null|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.where(df_train['Embarked'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing the null values in the Embarked column with the mode. \n",
    "df_train = df_train.na.fill('C', subset=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## checking\n",
    "df_train.where(df_train['Embarked'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "+-----------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.where(df_test.Embarked.isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is a code to create a wrapper for function, that works for both python and Pyspark.\n",
    "from typing import Callable\n",
    "from pyspark.sql import Column\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType, DataType\n",
    "class py_or_udf:\n",
    "    def __init__(self, returnType : DataType=StringType()):\n",
    "        self.spark_udf_type = returnType\n",
    "        \n",
    "    def __call__(self, func : Callable):\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            if any([isinstance(arg, Column) for arg in args]) or \\\n",
    "                any([isinstance(vv, Column) for vv in kwargs.values()]):\n",
    "                return udf(func, self.spark_udf_type)(*args, **kwargs)\n",
    "            else:\n",
    "                return func(*args, **kwargs)\n",
    "        return wrapped_func\n",
    "\n",
    "    \n",
    "@py_or_udf(returnType=StringType())\n",
    "def first_char(col):\n",
    "    return col[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn('Cabin', first_char(df_train['Cabin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn('Cabin', first_char(df_test['Cabin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500     N        S  \n",
       "1      0          PC 17599  71.2833     C        C  \n",
       "2      0  STON/O2. 3101282   7.9250     N        S  \n",
       "3      0            113803  53.1000     C        S  \n",
       "4      0            373450   8.0500     N        S  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the average of the fare column We can use pyspark's ***groupby*** function to get the mean fare of each cabin letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Cabin|         avg(Fare)|\n",
      "+-----+------------------+\n",
      "|    F| 18.69679230769231|\n",
      "|    E|46.026693749999986|\n",
      "|    T|              35.5|\n",
      "|    B|113.50576382978724|\n",
      "|    D| 57.24457575757576|\n",
      "|    C|100.15134067796612|\n",
      "|    A|39.623886666666664|\n",
      "|    N|  19.1573253275109|\n",
      "|    G|          13.58125|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy('Cabin').mean(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, these mean can help us determine the unknown cabins, if we compare each unknown cabin rows with the given mean's above. Let's write a simple function so that we can give cabin names based on the means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "@py_or_udf(returnType=StringType())\n",
    "def cabin_estimator(i):\n",
    "    \"\"\"Grouping cabin feature by the first letter\"\"\"\n",
    "    a = 0\n",
    "    if i<16:\n",
    "        a = \"G\"\n",
    "    elif i>=16 and i<27:\n",
    "        a = \"F\"\n",
    "    elif i>=27 and i<38:\n",
    "        a = \"T\"\n",
    "    elif i>=38 and i<47:\n",
    "        a = \"A\"\n",
    "    elif i>= 47 and i<53:\n",
    "        a = \"E\"\n",
    "    elif i>= 53 and i<54:\n",
    "        a = \"D\"\n",
    "    elif i>=54 and i<116:\n",
    "        a = 'C'\n",
    "    else:\n",
    "        a = \"B\"\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separating data where Cabin == 'N', remeber we used 'N' for Null. \n",
    "df_withN = df_train.filter(df_train['Cabin'] == 'N')\n",
    "df2 = df_train.filter(df_train['Cabin'] != 'N')\n",
    "\n",
    "## replacing 'N' using cabin estimated function. \n",
    "df_withN = df_withN.withColumn('Cabin', cabin_estimator(df_withN['Fare']))\n",
    "\n",
    "# putting the dataframe back together. \n",
    "df_train = df_withN.union(df2).orderBy('PassengerId') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do the same for test set\n",
    "df_testN = df_test.filter(df_test['Cabin'] == 'N')\n",
    "df_testNoN = df_test.filter(df_test['Cabin'] != 'N')\n",
    "df_testN = df_testN.withColumn('Cabin', cabin_estimator(df_testN['Fare']))\n",
    "df_test = df_testN.union(df_testNoN).orderBy('PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating UDF functions\n",
    "@py_or_udf(returnType=IntegerType())\n",
    "def name_length(name):\n",
    "    return len(name)\n",
    "\n",
    "\n",
    "@py_or_udf(returnType=StringType())\n",
    "def name_length_group(size):\n",
    "    a = ''\n",
    "    if (size <=20):\n",
    "        a = 'short'\n",
    "    elif (size <=35):\n",
    "        a = 'medium'\n",
    "    elif (size <=45):\n",
    "        a = 'good'\n",
    "    else:\n",
    "        a = 'long'\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the name length from name. \n",
    "df_train = df_train.withColumn(\"name_length\", name_length(df_train['Name']))\n",
    "\n",
    "## grouping based on name length. \n",
    "df_train = df_train.withColumn(\"nLength_group\", name_length_group(df_train['name_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's do the same for test set. \n",
    "df_test = df_test.withColumn(\"name_length\", name_length(df_test['Name']))\n",
    "\n",
    "df_test = df_test.withColumn(\"nLength_group\", name_length_group(df_test['name_length']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function helps getting the title from the name. \n",
    "@py_or_udf(returnType=StringType())\n",
    "def get_title(name):\n",
    "    return name.split('.')[0].split(',')[1].strip()\n",
    "\n",
    "df_train = df_train.withColumn(\"title\", get_title(df_train['Name']))\n",
    "df_test = df_test.withColumn('title', get_title(df_test['Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we are writing a function that can help us modify title column\n",
    "@py_or_udf(returnType=StringType())\n",
    "def fuse_title1(feature):\n",
    "    \"\"\"\n",
    "    This function helps modifying the title column\n",
    "    \"\"\"\n",
    "    if feature in ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col', 'Rev', 'Dona', 'Dr']:\n",
    "        return 'rare'\n",
    "    elif feature in ['Ms', 'Mlle']:\n",
    "        return 'Miss'\n",
    "    elif feature == 'Mme':\n",
    "        return 'Mrs'\n",
    "    else:\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn(\"title\", fuse_title1(df_train[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn(\"title\", fuse_title1(df_test['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr' 'Mrs' 'Miss' 'Master' 'rare']\n",
      "['Mr' 'Mrs' 'Miss' 'Master' 'rare']\n"
     ]
    }
   ],
   "source": [
    "print(df_train.toPandas()['title'].unique())\n",
    "print(df_test.toPandas()['title'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### family_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn(\"family_size\", df_train['SibSp']+df_train['Parch'])\n",
    "df_test = df_test.withColumn(\"family_size\", df_test['SibSp']+df_test['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bin the family size. \n",
    "@py_or_udf(returnType=StringType())\n",
    "def family_group(size):\n",
    "    \"\"\"\n",
    "    This funciton groups(loner, small, large) family based on family size\n",
    "    \"\"\"\n",
    "    \n",
    "    a = ''\n",
    "    if (size <= 1):\n",
    "        a = 'loner'\n",
    "    elif (size <= 4):\n",
    "        a = 'small'\n",
    "    else:\n",
    "        a = 'large'\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn(\"family_group\", family_group(df_train['family_size']))\n",
    "df_test = df_test.withColumn(\"family_group\", family_group(df_test['family_size']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "@py_or_udf(returnType=IntegerType())\n",
    "def is_alone(num):\n",
    "    if num<2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn(\"is_alone\", is_alone(df_train['family_size']))\n",
    "df_test = df_test.withColumn(\"is_alone\", is_alone(df_test[\"family_size\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping ticket column\n",
    "df_train = df_train.drop('ticket')\n",
    "df_test = df_test.drop(\"ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculated_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, when, coalesce, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here I am using a something similar to if and else statement, \n",
    "#when(condition, value_when_condition_met).otherwise(alt_condition)\n",
    "df_train = df_train.withColumn(\n",
    "    \"calculated_fare\", \n",
    "    when((col(\"Fare\")/col(\"family_size\")).isNull(), col('Fare'))\n",
    "    .otherwise((col(\"Fare\")/col(\"family_size\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn(\n",
    "    \"calculated_fare\", \n",
    "    when((col(\"Fare\")/col(\"family_size\")).isNull(), col('Fare'))\n",
    "    .otherwise((col(\"Fare\")/col(\"family_size\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fare_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "@py_or_udf(returnType=StringType())\n",
    "def fare_group(fare):\n",
    "    \"\"\"\n",
    "    This function creates a fare group based on the fare provided\n",
    "    \"\"\"\n",
    "    \n",
    "    a= ''\n",
    "    if fare <= 4:\n",
    "        a = 'Very_low'\n",
    "    elif fare <= 10:\n",
    "        a = 'low'\n",
    "    elif fare <= 20:\n",
    "        a = 'mid'\n",
    "    elif fare <= 45:\n",
    "        a = 'high'\n",
    "    else:\n",
    "        a = \"very_high\"\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn(\"fare_group\", fare_group(col(\"Fare\")))\n",
    "df_test = df_test.withColumn(\"fare_group\", fare_group(col(\"Fare\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all for today. Let's come back tomorrow when we will learn how to apply machine learning with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing, Bucketing & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv('../input/titanic/train.csv', header = True, inferSchema=True)\n",
    "test = spark.read.csv('../input/titanic/test.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarzing\n",
    "from pyspark.ml.feature import Binarizer\n",
    "# Cast the data type to double\n",
    "train = train.withColumn('SibSp', train['SibSp'].cast('double'))\n",
    "# Create binarzing transform\n",
    "bin = Binarizer(threshold=0.0, inputCol='SibSp', outputCol='SibSpBin')\n",
    "# Apply the transform\n",
    "train = bin.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|SibSp|SibSpBin|\n",
      "+-----+--------+\n",
      "|  1.0|     1.0|\n",
      "|  1.0|     1.0|\n",
      "|  0.0|     0.0|\n",
      "|  1.0|     1.0|\n",
      "|  0.0|     0.0|\n",
      "|  0.0|     0.0|\n",
      "|  0.0|     0.0|\n",
      "|  3.0|     1.0|\n",
      "|  0.0|     0.0|\n",
      "|  1.0|     1.0|\n",
      "+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('SibSp', 'SibSpBin').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "# We are going to bucket the fare column\n",
    "# Define the split\n",
    "splits = [0,4,10,20,45, float('Inf')]\n",
    "\n",
    "# Create bucketing transformer\n",
    "buck = Bucketizer(splits=splits, inputCol='Fare', outputCol='FareB')\n",
    "\n",
    "# Apply transformer\n",
    "train = buck.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>SibSpBin</th>\n",
       "      <th>FareB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0    0.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0    1.0   \n",
       "4                           Allen, Mr. William Henry    male  35.0    0.0   \n",
       "5                                   Moran, Mr. James    male   NaN    0.0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0    0.0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0    3.0   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0    0.0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0    1.0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  SibSpBin  FareB  \n",
       "0      0         A/5 21171   7.2500  None        S       1.0    1.0  \n",
       "1      0          PC 17599  71.2833   C85        C       1.0    4.0  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S       0.0    1.0  \n",
       "3      0            113803  53.1000  C123        S       1.0    4.0  \n",
       "4      0            373450   8.0500  None        S       0.0    1.0  \n",
       "5      0            330877   8.4583  None        Q       0.0    1.0  \n",
       "6      0             17463  51.8625   E46        S       0.0    4.0  \n",
       "7      1            349909  21.0750  None        S       1.0    3.0  \n",
       "8      2            347742  11.1333  None        S       0.0    2.0  \n",
       "9      0            237736  30.0708  None        C       1.0    3.0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "# it is a two step process\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "# Create indexer transformer for Sex Column\n",
    "\n",
    "# Step 1: Create indexer for texts\n",
    "stringIndexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "\n",
    "# fit transform\n",
    "model = stringIndexer.fit(train)\n",
    "\n",
    "# Apply transform\n",
    "indexed = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>SibSpBin</th>\n",
       "      <th>FareB</th>\n",
       "      <th>SexIndex</th>\n",
       "      <th>Sex_Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0    0.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0    1.0   \n",
       "4                           Allen, Mr. William Henry    male  35.0    0.0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  SibSpBin  FareB  SexIndex  \\\n",
       "0      0         A/5 21171   7.2500  None        S       1.0    1.0       0.0   \n",
       "1      0          PC 17599  71.2833   C85        C       1.0    4.0       1.0   \n",
       "2      0  STON/O2. 3101282   7.9250  None        S       0.0    1.0       1.0   \n",
       "3      0            113803  53.1000  C123        S       1.0    4.0       1.0   \n",
       "4      0            373450   8.0500  None        S       0.0    1.0       0.0   \n",
       "\n",
       "  Sex_Vec  \n",
       "0   (1.0)  \n",
       "1   (0.0)  \n",
       "2   (0.0)  \n",
       "3   (0.0)  \n",
       "4   (1.0)  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: One Hot Encode\n",
    "# Create encoder transformer\n",
    "encoder = OneHotEncoder(inputCol='SexIndex', outputCol='Sex_Vec')\n",
    "\n",
    "# fit model\n",
    "model = encoder.fit(indexed)\n",
    "\n",
    "# apply transform\n",
    "encoded_df = model.transform(indexed)\n",
    "\n",
    "encoded_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h1>Resources</h1>\n",
    "    <ul>\n",
    "        <li><a href=\"https://docs.databricks.com/spark/latest/spark-sql/udf-python.html\">User-defined functions - Python</a></li>\n",
    "        <li><a href=\"https://medium.com/@ayplam/developing-pyspark-udfs-d179db0ccc87\">Developing PySpark UDFs</a></li>\n",
    "    </ul>\n",
    "        <h1>Credits</h1>\n",
    "    <ul>\n",
    "        <li>To DataCamp, I have learned so much from DataCamp.</li>\n",
    "        <li>To Jose Portilla, Such an amazing teacher with all of his resources</li>\n",
    "    </ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>If you like to discuss any other projects or just have a chat about data science topics, I'll be more than happy to connect with you on:</h4>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.linkedin.com/in/masumrumi/\"><b>LinkedIn</b></a></li>\n",
    "        <li><a href=\"https://github.com/masumrumi\"><b>Github</b></a></li>\n",
    "        <li><a href=\"https://masumrumi.com/\"><b>masumrumi.com</b></a></li>\n",
    "        <li><a href=\"https://www.youtube.com/channel/UC1mPjGyLcZmsMgZ8SJgrfdw\"><b>Youtube</b></a></li>\n",
    "    </ul>\n",
    "\n",
    "<p>This kernel will always be a work in progress. I will incorporate new concepts of data science as I comprehend them with each update. If you have any idea/suggestions about this notebook, please let me know. Any feedback about further improvements would be genuinely appreciated.</p>\n",
    "\n",
    "<h1>If you have come this far, Congratulations!!</h1>\n",
    "\n",
    "<h1>If this notebook helped you in any way or you liked it, please upvote and/or leave a comment!! :)</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h1>Versions</h1>\n",
    "    <ul>\n",
    "        <li>Version 16</li>\n",
    "    </ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h1>Work Area</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other DataFrame Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium| Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(Age)|\n",
      "+--------+\n",
      "|    0.42|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agg\n",
    "df_train.agg({\"Age\" : \"min\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|   Sex|min_age|max_age|\n",
      "+------+-------+-------+\n",
      "|female|   0.75|   63.0|\n",
      "|  male|   0.42|   80.0|\n",
      "+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agg\n",
    "from pyspark.sql import functions as F\n",
    "df_train.groupBy(\"Sex\").agg(\n",
    "    F.min(\"Age\").name(\"min_age\"), \n",
    "    F.max(\"Age\").alias(\"max_age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|26.0|    0|    0|  7.925|    G|       S|         22|       medium| Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|35.0|    1|    0|   53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|35.0|    0|    0|   8.05|    G|       S|         24|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "+-----------+--------+------+--------------------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# colRegex\n",
    "df_train.select(df_train.colRegex(\"`(Sex)?+.+`\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Pclass|   Sex|\n",
      "+------+------+\n",
      "|     2|female|\n",
      "|     3|  male|\n",
      "|     1|  male|\n",
      "|     3|female|\n",
      "|     1|female|\n",
      "|     2|  male|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distinct\n",
    "df_train[['Pclass', 'Sex']].distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Pclass|   Sex|\n",
      "+------+------+\n",
      "|     2|female|\n",
      "|     3|  male|\n",
      "|     1|  male|\n",
      "|     3|female|\n",
      "|     1|female|\n",
      "|     2|  male|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another way\n",
    "# dropDuplicates\n",
    "df_train[['Pclass', 'Sex']].dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|30.0708|    T|       C|         35|       medium|  Mrs|          1|       loner|       1|        30.0708|      high|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# beware, this is probably not something we want when we try to do dropDuplicates\n",
    "df_train.dropDuplicates(subset=['Pclass']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Pclass|   Sex|\n",
      "+------+------+\n",
      "|     2|female|\n",
      "|     3|  male|\n",
      "|     1|  male|\n",
      "|     3|female|\n",
      "|     1|female|\n",
      "|     2|  male|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop_dupllicates()\n",
    "# drop_duplicates() is an alias of dropDuplicates()\n",
    "df_train[['Pclass', 'Sex']].drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          2|       1|     1|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          3|       1|     3|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium| Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          4|       1|     1|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|          5|       0|     3|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "+-----------+--------+------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop\n",
    "# dropping a column\n",
    "df_train.drop('Name').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Pclass|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          1|     3|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          2|     1|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          3|     3|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium| Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          4|     1|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|          5|     3|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "+-----------+------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop\n",
    "# dropping multiple columns\n",
    "df_train.drop(\"name\", \"Survived\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna\n",
    "df_train.dropna(how=\"any\", subset=[\"Age\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarly\n",
    "df_train.na.drop(how=\"any\", subset=['Age']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceptAll\n",
    "# temp dataframes\n",
    "df1 = spark.createDataFrame(\n",
    "        [(\"a\", 1), (\"a\", 1), (\"a\", 1), (\"a\", 2), (\"b\",  3), (\"c\", 4)], [\"C1\", \"C2\"])\n",
    "df2 = spark.createDataFrame([(\"a\", 1),(\"a\", 1), (\"b\", 3)], [\"C1\", \"C2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| C1| C2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  a|  1|\n",
      "|  a|  1|\n",
      "|  a|  2|\n",
      "|  b|  3|\n",
      "|  c|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| C1| C2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  a|  1|\n",
      "|  b|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| C1| C2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  a|  2|\n",
      "|  c|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.exceptAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| C1| C2|\n",
      "+---+---+\n",
      "|  b|  3|\n",
      "|  a|  1|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# intersect\n",
    "df1.intersect(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| C1| C2|\n",
      "+---+---+\n",
      "|  b|  3|\n",
      "|  a|  1|\n",
      "|  a|  1|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# intersectAll\n",
    "# intersectAll preserves the duplicates. \n",
    "df1.intersectAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns True if the collect() and take() methods can be run locally\n",
    "df_train.isLocal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group| title|family_size|family_group|is_alone|   calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|    Mr|          1|       loner|       1|              7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|   Mrs|          1|       loner|       1|           71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium|  Miss|          0|       loner|       1|             7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|   Mrs|          1|       loner|       1|              53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|    Mr|          0|       loner|       1|              8.05|       low|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0| 8.4583|    G|       Q|         16|        short|    Mr|          0|       loner|       1|            8.4583|       low|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|51.8625|    E|       S|         23|       medium|    Mr|          0|       loner|       1|           51.8625| very_high|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1| 21.075|    F|       S|         30|       medium|Master|          4|       small|       0|           5.26875|      high|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|11.1333|    G|       S|         49|         long|   Mrs|          2|       small|       0|           5.56665|       mid|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|30.0708|    T|       C|         35|       medium|   Mrs|          1|       loner|       1|           30.0708|      high|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|   16.7|    G|       S|         31|       medium|  Miss|          2|       small|       0|              8.35|       mid|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  26.55|    C|       S|         24|       medium|  Miss|          0|       loner|       1|             26.55|      high|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|   8.05|    G|       S|         30|       medium|    Mr|          0|       loner|       1|              8.05|       low|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5| 31.275|    T|       S|         27|       medium|    Mr|          6|       large|       0|5.2124999999999995|      high|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0| 7.8542|    G|       S|         36|         good|  Miss|          0|       loner|       1|            7.8542|       low|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|   16.0|    F|       S|         32|       medium|   Mrs|          0|       loner|       1|              16.0|       mid|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1| 29.125|    T|       Q|         20|        short|Master|          5|       large|       0|             5.825|      high|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|   13.0|    G|       S|         28|       medium|    Mr|          0|       loner|       1|              13.0|       mid|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|   18.0|    F|       S|         55|         long|   Mrs|          1|       loner|       1|              18.0|       mid|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|  7.225|    G|       C|         23|       medium|   Mrs|          0|       loner|       1|             7.225|       low|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## fillna\n",
    "df_train.fillna(\"N\", subset=['Cabin']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group| title|family_size|family_group|is_alone|   calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|    Mr|          1|       loner|       1|              7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|   Mrs|          1|       loner|       1|           71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium|  Miss|          0|       loner|       1|             7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|   Mrs|          1|       loner|       1|              53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|    Mr|          0|       loner|       1|              8.05|       low|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0| 8.4583|    G|       Q|         16|        short|    Mr|          0|       loner|       1|            8.4583|       low|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|51.8625|    E|       S|         23|       medium|    Mr|          0|       loner|       1|           51.8625| very_high|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1| 21.075|    F|       S|         30|       medium|Master|          4|       small|       0|           5.26875|      high|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|11.1333|    G|       S|         49|         long|   Mrs|          2|       small|       0|           5.56665|       mid|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|30.0708|    T|       C|         35|       medium|   Mrs|          1|       loner|       1|           30.0708|      high|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|   16.7|    G|       S|         31|       medium|  Miss|          2|       small|       0|              8.35|       mid|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  26.55|    C|       S|         24|       medium|  Miss|          0|       loner|       1|             26.55|      high|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|   8.05|    G|       S|         30|       medium|    Mr|          0|       loner|       1|              8.05|       low|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5| 31.275|    T|       S|         27|       medium|    Mr|          6|       large|       0|5.2124999999999995|      high|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0| 7.8542|    G|       S|         36|         good|  Miss|          0|       loner|       1|            7.8542|       low|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|   16.0|    F|       S|         32|       medium|   Mrs|          0|       loner|       1|              16.0|       mid|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1| 29.125|    T|       Q|         20|        short|Master|          5|       large|       0|             5.825|      high|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|   13.0|    G|       S|         28|       medium|    Mr|          0|       loner|       1|              13.0|       mid|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|   18.0|    F|       S|         55|         long|   Mrs|          1|       loner|       1|              18.0|       mid|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|  7.225|    G|       C|         23|       medium|   Mrs|          0|       loner|       1|             7.225|       low|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly\n",
    "# dataFrame.na.fill() is alias of dataFrame.fillna()\n",
    "df_train.na.fill(\"N\", subset=['Cabin']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = df_train.agg({\"Age\": \"mean\"}).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|              Age|Cabin|\n",
      "+-----------------+-----+\n",
      "|             22.0|    G|\n",
      "|             38.0|    C|\n",
      "|             26.0|    G|\n",
      "|             35.0|    C|\n",
      "|             35.0|    G|\n",
      "|29.69911764705882|    G|\n",
      "|             54.0|    E|\n",
      "|              2.0|    F|\n",
      "|             27.0|    G|\n",
      "|             14.0|    T|\n",
      "+-----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.fillna({\"Age\": age_mean, \"Cabin\": \"N\"})[['Age', \"Cabin\"]].show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Fare=7.25, Cabin='G', Embarked='S', name_length=23, nLength_group='medium', title='Mr', family_size=1, family_group='loner', is_alone=1, calculated_fare=7.25, fare_group='low')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first\n",
    "df_train.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(passenger):\n",
    "    print(passenger.Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foreach\n",
    "# this prints out in the terminal. \n",
    "df_train.foreach(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Cabin_freqItems|\n",
      "+--------------------+\n",
      "|[D, G, A, C, F, E...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# freqItems\n",
    "# this function is meant for exploratory data analysis.\n",
    "df_train.freqItems(cols=[\"Cabin\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  Fare|count|\n",
      "+------+-----+\n",
      "|  8.05|   43|\n",
      "|  13.0|   42|\n",
      "|7.8958|   38|\n",
      "|  7.75|   34|\n",
      "|  26.0|   31|\n",
      "|  10.5|   24|\n",
      "| 7.925|   18|\n",
      "| 7.775|   16|\n",
      "|7.2292|   15|\n",
      "|   0.0|   15|\n",
      "| 26.55|   15|\n",
      "|  7.25|   13|\n",
      "|8.6625|   13|\n",
      "|7.8542|   13|\n",
      "| 7.225|   12|\n",
      "|  16.1|    9|\n",
      "|   9.5|    9|\n",
      "| 24.15|    8|\n",
      "|  15.5|    8|\n",
      "|  14.5|    7|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy\n",
    "# pandas value_counts() equivalent. \n",
    "df_train.groupBy(\"Fare\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+\n",
      "|   Sex|Pclass|count|\n",
      "+------+------+-----+\n",
      "|  male|     3|  347|\n",
      "|female|     3|  144|\n",
      "|female|     1|   94|\n",
      "|female|     2|   76|\n",
      "|  male|     2|  108|\n",
      "|  male|     1|  122|\n",
      "+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy(['Sex', 'Pclass']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group| title|family_size|family_group|is_alone|   calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|    Mr|          1|       loner|       1|              7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|   Mrs|          1|       loner|       1|           71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium|  Miss|          0|       loner|       1|             7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|   Mrs|          1|       loner|       1|              53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|    Mr|          0|       loner|       1|              8.05|       low|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0| 8.4583|    G|       Q|         16|        short|    Mr|          0|       loner|       1|            8.4583|       low|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|51.8625|    E|       S|         23|       medium|    Mr|          0|       loner|       1|           51.8625| very_high|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1| 21.075|    F|       S|         30|       medium|Master|          4|       small|       0|           5.26875|      high|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|11.1333|    G|       S|         49|         long|   Mrs|          2|       small|       0|           5.56665|       mid|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|30.0708|    T|       C|         35|       medium|   Mrs|          1|       loner|       1|           30.0708|      high|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|   16.7|    G|       S|         31|       medium|  Miss|          2|       small|       0|              8.35|       mid|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  26.55|    C|       S|         24|       medium|  Miss|          0|       loner|       1|             26.55|      high|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|   8.05|    G|       S|         30|       medium|    Mr|          0|       loner|       1|              8.05|       low|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5| 31.275|    T|       S|         27|       medium|    Mr|          6|       large|       0|5.2124999999999995|      high|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0| 7.8542|    G|       S|         36|         good|  Miss|          0|       loner|       1|            7.8542|       low|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|   16.0|    F|       S|         32|       medium|   Mrs|          0|       loner|       1|              16.0|       mid|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1| 29.125|    T|       Q|         20|        short|Master|          5|       large|       0|             5.825|      high|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|   13.0|    G|       S|         28|       medium|    Mr|          0|       loner|       1|              13.0|       mid|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|   18.0|    F|       S|         55|         long|   Mrs|          1|       loner|       1|              18.0|       mid|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|  7.225|    G|       C|         23|       medium|   Mrs|          0|       loner|       1|             7.225|       low|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.hint(\"broadcast\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isStreaming\n",
    "# Returns True if this DataFrame contains one or more sources that continuously return data as it arrives.\n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.isStreaming.html\n",
    "df_train.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|    Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|        124|       1|     2| Webber, Miss. Susan|female|32.5|    0|    0|    13.0|    E|       S|         19|        short| Miss|          0|       loner|       1|           13.0|       mid|\n",
      "|        299|       1|     1|Saalfeld, Mr. Ado...|  male|null|    0|    0|    30.5|    C|       S|         21|       medium|   Mr|          0|       loner|       1|           30.5|      high|\n",
      "|        129|       1|     3|   Peter, Miss. Anna|female|null|    1|    1| 22.3583|    F|       C|         17|        short| Miss|          2|       small|       0|       11.17915|      high|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|    53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|        137|       1|     1|Newsom, Miss. Hel...|female|19.0|    0|    2| 26.2833|    D|       S|         28|       medium| Miss|          2|       small|       0|       13.14165|      high|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|    16.7|    G|       S|         31|       medium| Miss|          2|       small|       0|           8.35|       mid|\n",
      "|        152|       1|     1|Pears, Mrs. Thoma...|female|22.0|    1|    0|    66.6|    C|       S|         33|       medium|  Mrs|          1|       loner|       1|           66.6| very_high|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|    13.0|    D|       S|         21|       medium|   Mr|          0|       loner|       1|           13.0|       mid|\n",
      "|        167|       1|     1|Chibnall, Mrs. (E...|female|null|    0|    1|    55.0|    E|       S|         38|         good|  Mrs|          1|       loner|       1|           55.0| very_high|\n",
      "|        195|       1|     1|Brown, Mrs. James...|female|44.0|    0|    0| 27.7208|    B|       C|         41|         good|  Mrs|          0|       loner|       1|        27.7208|      high|\n",
      "|        196|       1|     1|Lurette, Miss. Elise|female|58.0|    0|    0|146.5208|    B|       C|         20|        short| Miss|          0|       loner|       1|       146.5208| very_high|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0| 76.7292|    D|       C|         40|         good|  Mrs|          1|       loner|       1|        76.7292| very_high|\n",
      "|        210|       1|     1|    Blank, Mr. Henry|  male|40.0|    0|    0|    31.0|    A|       C|         16|        short|   Mr|          0|       loner|       1|           31.0|      high|\n",
      "|         62|       1|     1| Icard, Miss. Amelie|female|38.0|    0|    0|    80.0|    B|       C|         19|        short| Miss|          0|       loner|       1|           80.0| very_high|\n",
      "|        216|       1|     1|Newell, Miss. Mad...|female|31.0|    1|    0| 113.275|    D|       C|         23|       medium| Miss|          1|       loner|       1|        113.275| very_high|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|   263.0|    C|       S|         26|       medium| Miss|          5|       large|       0|           52.6| very_high|\n",
      "|        219|       1|     1|Bazzani, Miss. Al...|female|32.0|    0|    0| 76.2917|    D|       C|         21|       medium| Miss|          0|       loner|       1|        76.2917| very_high|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| 71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|        225|       1|     1|Hoyt, Mr. Frederi...|  male|38.0|    1|    0|    90.0|    C|       S|         28|       medium|   Mr|          1|       loner|       1|           90.0| very_high|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|    35.5|    A|       S|         28|       medium|   Mr|          0|       loner|       1|           35.5|      high|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort/orderBy\n",
    "df_train.sort('Survived', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomSplit\n",
    "# randomly splits the dataframe into two based on the given weights.\n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html\n",
    "splits = df_train.randomSplit([1.0, 2.0], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0| 8.4583|    G|       Q|         16|        short|   Mr|          0|       loner|       1|         8.4583|       low|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|   8.05|    G|       S|         30|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "|         23|       1|     3|\"McGowan, Miss. A...|female|15.0|    0|    0| 8.0292|    G|       Q|         31|       medium| Miss|          0|       loner|       1|         8.0292|       low|\n",
      "|         26|       1|     3|Asplund, Mrs. Car...|female|38.0|    1|    5|31.3875|    T|       S|         57|         long|  Mrs|          6|       large|       0|        5.23125|      high|\n",
      "|         35|       0|     1|Meyer, Mr. Edgar ...|  male|28.0|    1|    0|82.1708|    C|       C|         23|       medium|   Mr|          1|       loner|       1|        82.1708| very_high|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits[0].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group| title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+---------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|    G|       S|         23|       medium|    Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium|  Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|    G|       S|         24|       medium|    Mr|          0|       loner|       1|           8.05|       low|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1| 21.075|    F|       S|         30|       medium|Master|          4|       small|       0|        5.26875|      high|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|11.1333|    G|       S|         49|         long|   Mrs|          2|       small|       0|        5.56665|       mid|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+------+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits[1].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|   Man|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium| Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|   Man|35.0|    0|    0|   8.05|    G|       S|         24|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace\n",
    "df_train.replace(\"male\", \"Man\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Cabin|Embarked|name_length|nLength_group|title|family_size|family_group|is_alone|calculated_fare|fare_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|   Man|22.0|    1|    0|   7.25|    G|       S|         23|       medium|   Mr|          1|       loner|       1|           7.25|       low|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|    C|       C|         51|         long|  Mrs|          1|       loner|       1|        71.2833| very_high|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|    G|       S|         22|       medium| Miss|          0|       loner|       1|          7.925|       low|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|    C|       S|         44|         good|  Mrs|          1|       loner|       1|           53.1| very_high|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|   Man|35.0|    0|    0|   8.05|    G|       S|         24|       medium|   Mr|          0|       loner|       1|           8.05|       low|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-----+--------+-----------+-------------+-----+-----------+------------+--------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similarly\n",
    "df_train.na.replace(\"male\", \"Man\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  x|  y|\n",
      "+---+---+\n",
      "|foo|  1|\n",
      "|foo|  2|\n",
      "|bar|  2|\n",
      "|bar|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cube\n",
    "# the following stack overflow explains cube better than official spark page. \n",
    "# https://stackoverflow.com/questions/37975227/what-is-the-difference-between-cube-rollup-and-groupby-operators\n",
    "df = spark.createDataFrame([(\"foo\", 1), (\"foo\", 2), (\"bar\", 2), (\"bar\", 2)]).toDF(\"x\", \"y\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|         Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|male|22.0|    1|    0|      A/5 21171|   7.25| null|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|male|35.0|    0|    0|         373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|male|null|    0|    0|         330877| 8.4583| null|       Q|\n",
      "|          8|       0|     3|Palsson, Master. ...|male| 2.0|    3|    1|         349909| 21.075| null|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|male|20.0|    0|    0|      A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|male|39.0|    1|    5|         347082| 31.275| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|male| 2.0|    4|    1|         382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|male|null|    0|    0|         244373|   13.0| null|       S|\n",
      "|         21|       0|     2|Fynney, Mr. Joseph J|male|35.0|    0|    0|         239865|   26.0| null|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|male|34.0|    0|    0|         248698|   13.0|  D56|       S|\n",
      "|         27|       0|     3|Emir, Mr. Farred ...|male|null|    0|    0|           2631|  7.225| null|       C|\n",
      "|         30|       0|     3| Todoroff, Mr. Lalio|male|null|    0|    0|         349216| 7.8958| null|       S|\n",
      "|         31|       0|     1|Uruchurtu, Don. M...|male|40.0|    0|    0|       PC 17601|27.7208| null|       C|\n",
      "|         34|       0|     2|Wheadon, Mr. Edwa...|male|66.0|    0|    0|     C.A. 24579|   10.5| null|       S|\n",
      "|         37|       1|     3|    Mamee, Mr. Hanna|male|null|    0|    0|           2677| 7.2292| null|       C|\n",
      "|         38|       0|     3|Cann, Mr. Ernest ...|male|21.0|    0|    0|     A./5. 2152|   8.05| null|       S|\n",
      "|         43|       0|     3| Kraeff, Mr. Theodor|male|null|    0|    0|         349253| 7.8958| null|       C|\n",
      "|         46|       0|     3|Rogers, Mr. Willi...|male|null|    0|    0|S.C./A.4. 23567|   8.05| null|       S|\n",
      "|         47|       0|     3|   Lennon, Mr. Denis|male|null|    1|    0|         370371|   15.5| null|       Q|\n",
      "|         49|       0|     3| Samaan, Mr. Youssef|male|null|    2|    0|           2662|21.6792| null|       C|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|   x|   y|count|\n",
      "+----+----+-----+\n",
      "| foo|   1|    1|\n",
      "| foo|   2|    1|\n",
      "| bar|   2|    2|\n",
      "|null|null|    4|\n",
      "|null|   2|    3|\n",
      "|null|   1|    1|\n",
      "| bar|null|    2|\n",
      "| foo|null|    2|\n",
      "+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cube(\"x\", \"y\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what cube returns\n",
    "```\n",
    "// +----+----+-----+     \n",
    "// |   x|   y|count|\n",
    "// +----+----+-----+\n",
    "// | foo|   1|    1|   <- count of records where x = foo AND y = 1\n",
    "// | foo|   2|    1|   <- count of records where x = foo AND y = 2\n",
    "// | bar|   2|    2|   <- count of records where x = bar AND y = 2\n",
    "// |null|null|    4|   <- total count of records\n",
    "// |null|   2|    3|   <- count of records where y = 2\n",
    "// |null|   1|    1|   <- count of records where y = 1\n",
    "// | bar|null|    2|   <- count of records where x = bar\n",
    "// | foo|null|    2|   <- count of records where x = foo\n",
    "// +----+----+-----+```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|   x|   y|count|\n",
      "+----+----+-----+\n",
      "| foo|   1|    1|\n",
      "| foo|   2|    1|\n",
      "| bar|   2|    2|\n",
      "|null|null|    4|\n",
      "| bar|null|    2|\n",
      "| foo|null|    2|\n",
      "+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rollup\n",
    "df.rollup(\"x\", \"y\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what rollup's look like\n",
    "```\n",
    "// +----+----+-----+\n",
    "// |   x|   y|count|\n",
    "// +----+----+-----+\n",
    "// | foo|null|    2|   <- count where x is fixed to foo\n",
    "// | bar|   2|    2|   <- count where x is fixed to bar and y is fixed to  2\n",
    "// | foo|   1|    1|   ...\n",
    "// | foo|   2|    1|   ...\n",
    "// |null|null|    4|   <- count where no column is fixed\n",
    "// | bar|null|    2|   <- count where x is fixed to bar\n",
    "// +----+----+-----+```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sameSemantics\n",
    "# Returns True when the logical query plans inside both DataFrames are equal and therefore return same results.\n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sameSemantics.html\n",
    "df1 = spark.range(10)\n",
    "df2 = spark.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.withColumn(\"col1\", df1.id * 2).sameSemantics(df2.withColumn(\"col1\", df2.id * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.withColumn(\"col1\", df1.id * 2).sameSemantics(df2.withColumn(\"col1\", df2.id + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.withColumn(\"col1\", df1.id * 2).sameSemantics(df2.withColumn(\"col0\", df2.id * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(PassengerId,IntegerType,true),StructField(Survived,IntegerType,true),StructField(Pclass,IntegerType,true),StructField(Name,StringType,true),StructField(Sex,StringType,true),StructField(Age,DoubleType,true),StructField(SibSp,IntegerType,true),StructField(Parch,IntegerType,true),StructField(Fare,DoubleType,true),StructField(Cabin,StringType,true),StructField(Embarked,StringType,false),StructField(name_length,IntegerType,true),StructField(nLength_group,StringType,true),StructField(title,StringType,true),StructField(family_size,IntegerType,true),StructField(family_group,StringType,true),StructField(is_alone,IntegerType,true),StructField(calculated_fare,DoubleType,true),StructField(fare_group,StringType,true)))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- name_length: integer (nullable = true)\n",
      " |-- nLength_group: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- family_size: integer (nullable = true)\n",
      " |-- family_group: string (nullable = true)\n",
      " |-- is_alone: integer (nullable = true)\n",
      " |-- calculated_fare: double (nullable = true)\n",
      " |-- fare_group: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
